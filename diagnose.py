#!/usr/bin/env python3
"""ç³»ç»Ÿè¯Šæ–­è„šæœ¬ - æ£€æŸ¥æ‰€æœ‰é…ç½®å’Œä¾èµ–"""

import sys
import os
from pathlib import Path

def check_env_file():
    """æ£€æŸ¥ .env æ–‡ä»¶"""
    print("\n" + "="*60)
    print("1. æ£€æŸ¥ç¯å¢ƒé…ç½®æ–‡ä»¶")
    print("="*60)
    
    env_path = Path(".env")
    if not env_path.exists():
        print("âŒ .env æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    print("âœ… .env æ–‡ä»¶å­˜åœ¨")
    
    # è¯»å–å…³é”®é…ç½®
    with open(env_path) as f:
        content = f.read()
        
    required_keys = ["OPENAI_API_KEY", "OPENAI_BASE_URL", "OPENAI_MODEL"]
    for key in required_keys:
        if key in content:
            print(f"âœ… {key} å·²é…ç½®")
        else:
            print(f"âš ï¸  {key} æœªé…ç½®")
    
    return True

def check_dependencies():
    """æ£€æŸ¥ä¾èµ–åŒ…"""
    print("\n" + "="*60)
    print("2. æ£€æŸ¥ä¾èµ–åŒ…")
    print("="*60)
    
    required_packages = [
        "fastapi",
        "uvicorn",
        "langchain_openai",
        "arxiv",
        "httpx",
        "asyncpg",
        "qdrant_client",
        "feedparser",
        "beautifulsoup4"
    ]
    
    missing = []
    for package in required_packages:
        try:
            __import__(package.replace("-", "_"))
            print(f"âœ… {package}")
        except ImportError:
            print(f"âŒ {package} - ç¼ºå¤±")
            missing.append(package)
    
    if missing:
        print(f"\nâš ï¸  ç¼ºå¤±çš„åŒ…: {', '.join(missing)}")
        print(f"å®‰è£…å‘½ä»¤: pip install {' '.join(missing)}")
        return False
    
    return True

def check_config():
    """æ£€æŸ¥é…ç½®åŠ è½½"""
    print("\n" + "="*60)
    print("3. æ£€æŸ¥é…ç½®åŠ è½½")
    print("="*60)
    
    try:
        from core.config import get_config
        config = get_config()
        
        print(f"âœ… é…ç½®åŠ è½½æˆåŠŸ")
        print(f"   - API Key: {'å·²è®¾ç½®' if config.llm.api_key else 'æœªè®¾ç½®'}")
        print(f"   - Base URL: {config.llm.base_url or 'æœªè®¾ç½®'}")
        print(f"   - Model: {config.llm.model_name}")
        print(f"   - Debug: {config.debug}")
        
        return True
    except Exception as e:
        print(f"âŒ é…ç½®åŠ è½½å¤±è´¥: {str(e)}")
        return False

def check_api_routes():
    """æ£€æŸ¥ API è·¯ç”±"""
    print("\n" + "="*60)
    print("4. æ£€æŸ¥ API è·¯ç”±")
    print("="*60)
    
    try:
        from api.main import app
        
        routes = []
        for route in app.routes:
            if hasattr(route, 'path'):
                routes.append(route.path)
        
        print(f"âœ… API åŠ è½½æˆåŠŸï¼Œå…± {len(routes)} ä¸ªè·¯ç”±")
        
        # æ£€æŸ¥å…³é”®è·¯ç”±
        key_routes = ["/", "/health", "/api/v1/papers/search", "/api/v1/analysis/analyze"]
        for route in key_routes:
            if route in routes:
                print(f"   âœ… {route}")
            else:
                print(f"   âŒ {route} - ç¼ºå¤±")
        
        return True
    except Exception as e:
        print(f"âŒ API åŠ è½½å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def check_frontend():
    """æ£€æŸ¥å‰ç«¯æ–‡ä»¶"""
    print("\n" + "="*60)
    print("5. æ£€æŸ¥å‰ç«¯æ–‡ä»¶")
    print("="*60)
    
    frontend_files = [
        "frontend/index.html",
        "frontend/static/css/style.css",
        "frontend/static/js/app.js"
    ]
    
    all_exist = True
    for file_path in frontend_files:
        path = Path(file_path)
        if path.exists():
            print(f"âœ… {file_path}")
        else:
            print(f"âš ï¸  {file_path} - ä¸å­˜åœ¨ï¼ˆå¯é€‰ï¼‰")
    
    return True

def check_llm_connection():
    """æ£€æŸ¥ LLM è¿æ¥"""
    print("\n" + "="*60)
    print("6. æ£€æŸ¥ LLM è¿æ¥")
    print("="*60)
    
    try:
        import asyncio
        from langchain_openai import ChatOpenAI
        from core.config import get_config
        
        config = get_config()
        
        if not config.llm.api_key:
            print("âš ï¸  API Key æœªè®¾ç½®ï¼Œè·³è¿‡è¿æ¥æµ‹è¯•")
            return True
        
        async def test():
            llm = ChatOpenAI(
                model=config.llm.model_name,
                temperature=0.7,
                api_key=config.llm.api_key,
                base_url=config.llm.base_url
            )
            
            response = await llm.ainvoke("æµ‹è¯•")
            return response.content
        
        print("æ­£åœ¨æµ‹è¯• LLM è¿æ¥...")
        result = asyncio.run(test())
        print(f"âœ… LLM è¿æ¥æˆåŠŸ")
        print(f"   æ¨¡å‹å“åº”: {result[:50]}...")
        
        return True
    except Exception as e:
        print(f"âŒ LLM è¿æ¥å¤±è´¥: {str(e)}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "="*60)
    print("InnoCore AI ç³»ç»Ÿè¯Šæ–­")
    print("="*60)
    
    results = []
    
    results.append(("ç¯å¢ƒé…ç½®", check_env_file()))
    results.append(("ä¾èµ–åŒ…", check_dependencies()))
    results.append(("é…ç½®åŠ è½½", check_config()))
    results.append(("API è·¯ç”±", check_api_routes()))
    resul)
 main(__":
    "__main __name__ ==\n")

if"*60 + ""=   print(
    
 )ä¿®å¤é—®é¢˜ã€‚"æœªé€šè¿‡ï¼Œè¯·æ ¹æ®ä¸Šè¿°æç¤ºâš ï¸  éƒ¨åˆ†æ£€æŸ¥print("\n         else:
n.py")
   thon ru: py("\nå¯åŠ¨å‘½ä»¤      print")
  è¡Œã€‚ä»¥æ­£å¸¸è¿æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼ç³»ç»Ÿå¯rint("\nğŸ‰        pd:
 seasll_p   if a
    
 lts) r in resufor1] all(r[sed = all_pas  
      status}")
me}: {print(f"{na       "
 "âŒ å¤±è´¥e lsif result e" é€šè¿‡us = "âœ…         statts:
sul in resultname, re    for    
="*60)
     print("æ€»ç»“")
int("è¯Šæ–­0)
    pr + "="*6\n"rint("ç»“
    p# æ€»       

 ion()))nnecteck_llm_co, ch(("LLM è¿æ¥"s.append
    resultend()))nt_fro", checkd(("å‰ç«¯æ–‡ä»¶ts.appen